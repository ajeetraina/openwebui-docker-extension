services:
  # OpenWebUI service configured for Docker Model Runner
  openwebui:
    build:
      context: .
      dockerfile: Dockerfile
    image: openwebui-model-runner:latest
    container_name: openwebui-model-runner
    env_file: './backend.env'
    volumes:
      - openwebui-data:/app/backend/data
    ports:
      - "${OPENWEBUI_PORT-3001}:8080"
    environment:
      # Docker Model Runner Configuration
      - 'OPENAI_API_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1'
      - 'OPENAI_API_KEY=dockermodelrunner'
      
      # Disable Ollama, use Docker Model Runner
      - 'ENABLE_OLLAMA_API=false'
      - 'ENABLE_OPENAI_API=true'
      
      # WebUI Configuration
      - 'WEBUI_NAME=OpenWebUI + Docker Model Runner'
      - 'WEBUI_SECRET_KEY='
      - 'WEBUI_AUTH=false'
      - 'ENABLE_SIGNUP=true'
      - 'DEFAULT_USER_ROLE=user'
      
      # Enhanced Features
      - 'ENABLE_MODEL_FILTER=true'
      - 'ENABLE_COMMUNITY_SHARING=false'
      - 'CORS_ALLOW_ORIGIN=*'
    
    extra_hosts:
      - "host.docker.internal:host-gateway"
      - "model-runner.docker.internal:host-gateway"
    
    networks:
      - openwebui-network
    
    restart: unless-stopped
    
    labels:
      - "com.docker.desktop.extension=true"
      - "com.docker.desktop.extension.api.version=>=0.3.4"
      - "openwebui.model-runner=true"

volumes:
  openwebui-data:
    driver: local
    labels:
      - "openwebui.data=true"

networks:
  openwebui-network:
    driver: bridge
    labels:
      - "openwebui.network=true"
