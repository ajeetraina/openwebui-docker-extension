# Docker Model Runner Configuration (llama.cpp engine)
BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/
MODEL=ai/llama3.2:1B-Q8_0
API_KEY=${API_KEY:-dockermodelrunner}

# Alternative: Use Docker Compose model provider
OLLAMA_BASE_URL=http://llm:11434
LLM_MODEL_NAME=ai/llama3.2:1B-Q8_0

# OpenWebUI Configuration
WEBUI_NAME=OpenWebUI + Model Runner
WEBUI_AUTH=false
ENABLE_SIGNUP=true
ENABLE_OLLAMA_API=false
ENABLE_OPENAI_API=true

# OpenAI-compatible API settings (for Model Runner)
OPENAI_API_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1
OPENAI_API_KEY=dockermodelrunner


# Docker Integration
DOCKER_HOST=unix:///var/run/docker.sock

TRACING_ENABLED=true

# Security
CORS_ALLOW_ORIGIN=*
ENABLE_MODEL_FILTER=true
ENABLE_COMMUNITY_SHARING=false
