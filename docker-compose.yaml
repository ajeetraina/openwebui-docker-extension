services:
  openwebui:
    image: ajeetraina777/openwebui-docker-extension:2.0
    container_name: openwebui-model-runner
    volumes:
      - openwebui-data:/app/backend/data
    ports:
      - "8090:8080"
    environment:
      - OPENAI_API_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1
      - OPENAI_API_KEY=dockermodelrunner
      - ENABLE_OLLAMA_API=false
      - ENABLE_OPENAI_API=true
      - WEBUI_NAME=OpenWebUI + Docker Model Runner
      - WEBUI_AUTH=false
      - ENABLE_SIGNUP=true
      - DEFAULT_USER_ROLE=user
      - ENABLE_MODEL_FILTER=true
      - ENABLE_COMMUNITY_SHARING=false
      - CORS_ALLOW_ORIGIN=*
    extra_hosts:
      - "host.docker.internal:host-gateway"
      - "model-runner.docker.internal:host-gateway"
    networks:
      - openwebui-network
    restart: unless-stopped
    labels:
      - "com.docker.desktop.extension=true"
      - "com.docker.desktop.extension.api.version=>=0.3.4"

volumes:
  openwebui-data:
    driver: local

networks:
  openwebui-network:
    driver: bridge
